{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6fe4086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_1_1 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide explicitly refers to the country India even if it does not discuss any specific events or issues related to India.,\n",
    "using terms such as 'India', 'Indian', 'Bharat', or 'New Delhi' or else.\n",
    "\n",
    "Do not count ambiguous uses (e.g., 'Indian hemp', Native Americans, etc.).\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "If the indian terms are used in the article, then the answer is 'yes' directly.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1e17218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_1_2 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide mentions a well-known or important Indian public figure or institution,\n",
    "such as Narendra Modi, S. Jaishankar, DRDO, Tata, Infosys, or any other individual or organization strongly associated with the Indian state.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d7e98084",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_1_3 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide mentions a well-known Indian public figure or institution,\n",
    "such as Narendra Modi, S. Jaishankar, DRDO, Tata, Infosys, or any other individual or organization strongly associated with the Indian state.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "45f0d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_2_1 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide describe an event or issue occuring in India.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4d5a4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_2_2 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide deals with Indian's institutions, such as the Indian government, Indian intelligence services, or internationnal relation.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fca8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_2_3 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide deals with Indian people, such as Indian citizens, Indian residents, or any other individuals or groups specifically identified as being from India.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "09ae87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_2_4 = \"\"\"[INST]\n",
    "    Your task is to determine whether the article I will provide deals with Indian's religion, such as Hinduism, Islam, Christianity, Sikhism, Buddhism, or any other religious aspect specifically related to India.\n",
    "\n",
    "    Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "    Use the following format strictly:\n",
    "    `This article {{explanation (one sentence)}}\n",
    "    So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "    Here is the article:\n",
    "    {article}\n",
    "\n",
    "    Your answer:\n",
    "    [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33dbd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the article can change the image you have of india\n",
    "prompt_Q_2_5 = \"\"\"[INST]\n",
    "    Your task is to determine whether the article I will provide may change the image you have of India, such as its culture, society, or any other aspect that could influence your perception of the country.\n",
    "\n",
    "    Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "    Use the following format strictly:\n",
    "    `This article {{explanation (one sentence)}}\n",
    "    So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "    Here is the article:\n",
    "    {article}\n",
    "\n",
    "    Your answer:\n",
    "    [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ae84a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_3_1 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide only deals with sports events, like result with no other subject.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b61b2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_3_2 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide only deals with celebrity gossip or entertainment news related to India or Indian celebrities.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1cbf8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_3_3 = \"\"\"[INST]\n",
    "Your task is to determine whether the article I will provide only deals with marketing, advertising, or commercial content related to India or Indian products without political or geopolitical  scope.\n",
    "\n",
    "Explain you resonnement then answer with 'yes' or 'no'.\n",
    "\n",
    "Use the following format strictly:\n",
    "`This article {{explanation (one sentence)}}\n",
    " So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "Here is the article:\n",
    "{article}\n",
    "\n",
    "Your answer:\n",
    "[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "543de44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Q_3_4 = \"\"\"[INST]\n",
    "    Your task is to determine whether the article I will provide deals with political, economical, social or other importante subject.\n",
    "\n",
    "    Explain you resonnement then answer with 'yes' or 'no'.\n",
    "    answer 'yes' if the article deals with importante subject.\n",
    "\n",
    "    Use the following format strictly:\n",
    "    `This article {{explanation (one sentence)}}\n",
    "    So the answer is {{[yes], [no]}}.`\n",
    "\n",
    "    Here is the article:\n",
    "    {article}\n",
    "\n",
    "    Your answer:\n",
    "    [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c81ef15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joris/kutniti/article_ai_analyser/tree_questioning\n"
     ]
    }
   ],
   "source": [
    "# Génération de l’arborescence JSON de base\n",
    "tree = {\n",
    "    \"nodes\": {},\n",
    "    \"leaves\": {\n",
    "        \"LEAF_YES\": \"POSITIVE\",\n",
    "        \"LEAF_NO\": \"IRRELEVANT\"\n",
    "    },\n",
    "    \"root\": \"Q_1_1\",\n",
    "    \"min_size\": 200 \n",
    "}\n",
    "\n",
    "def add_node_to_tree(tree, name, prompt, if_yes, if_no):\n",
    "    tree[\"nodes\"][name] = {\n",
    "        \"prompt\": prompt,\n",
    "        \"question_name\": name,\n",
    "        \"if_yes\": if_yes,\n",
    "        \"if_no\": if_no\n",
    "    }\n",
    "\n",
    "# Construction de l'arbre simple\n",
    "add_node_to_tree(tree, \"Q_1_1\", prompt_Q_1_1, \"Q_3_1\", \"Q_1_2\")\n",
    "add_node_to_tree(tree, \"Q_1_2\", prompt_Q_1_2, \"Q_3_1\", \"Q_2_1\")\n",
    "# add_node_to_tree(tree, \"Q_1_3\", prompt_Q_1_3, \"Q_3_1\", \"Q_2_1\")\n",
    "add_node_to_tree(tree, \"Q_2_1\", prompt_Q_2_1, \"Q_3_1\", \"Q_2_2\")\n",
    "add_node_to_tree(tree, \"Q_2_2\", prompt_Q_2_2, \"Q_3_1\", \"Q_2_3\")\n",
    "add_node_to_tree(tree, \"Q_2_3\", prompt_Q_2_3, \"Q_3_1\", \"Q_2_4\")\n",
    "add_node_to_tree(tree, \"Q_2_4\", prompt_Q_2_4, \"Q_3_1\", \"Q_2_5\")\n",
    "add_node_to_tree(tree, \"Q_2_5\", prompt_Q_2_5, \"Q_3_1\", \"LEAF_NO\")\n",
    "add_node_to_tree(tree, \"Q_3_1\", prompt_Q_3_1, \"Q_3_4\", \"Q_3_2\")\n",
    "add_node_to_tree(tree, \"Q_3_2\", prompt_Q_3_2, \"Q_3_4\", \"Q_3_3\")\n",
    "add_node_to_tree(tree, \"Q_3_3\", prompt_Q_3_3, \"Q_3_4\", \"LEAF_YES\")\n",
    "add_node_to_tree(tree, \"Q_3_4\", prompt_Q_3_4, \"LEAF_YES\", \"LEAF_NO\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "#check where i am\n",
    "print(Path.cwd())\n",
    "\n",
    "# Sauvegarde du JSONl\n",
    "json_path = Path(\"/home/joris/kutniti/article_ai_analyser/tree_questioning/relevant_question_tree.json\") #change this path to your desired location\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(tree, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "936d93d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "INFO:root:Fresh start enabled. Deleting treated file.\n",
      "[WARNING] Treated file 'relevancy_treated.json' not found. Starting with an empty list.\n",
      "[INFO] Loaded index with 10352 items from '../../data/index.csv'.\n",
      "[INFO] Processing article: 4e04d7cd-7696-48ac-9845-74e116dbe38a_f5645044731949eeae89e3bab078338e - 4e04d7cd-7696-48ac-9845-74e116dbe38a_f5645044731949eeae89e3bab078338e.txt\n",
      "[INFO] Total marked 1 items as treated.                                         \n",
      "[INFO] Processing article: 34e4ebcb-51ff-428a-80dd-8166d9b903d0_c14b932a903c457983329e2777e33c6f - 34e4ebcb-51ff-428a-80dd-8166d9b903d0_c14b932a903c457983329e2777e33c6f.txt\n",
      "[INFO] Total marked 2 items as treated.                                         \n",
      "[INFO] Processing article: 57b7ff26-0e7d-47c6-ba0f-b24ea4eec93e_dfadfe8a02c64ebbb7cff3915902f177 - 57b7ff26-0e7d-47c6-ba0f-b24ea4eec93e_dfadfe8a02c64ebbb7cff3915902f177.txt\n",
      "[INFO] Total marked 3 items as treated.                                         \n",
      "[INFO] Processing article: 55e26c3e-7e38-447c-a5f5-14947ba1d637_bf7a66a74af84f8c8f2587bd8ed8d3c8 - 55e26c3e-7e38-447c-a5f5-14947ba1d637_bf7a66a74af84f8c8f2587bd8ed8d3c8.txt\n",
      "[INFO] Total marked 4 items as treated.                                         \n",
      "[INFO] Processing article: 255e00c9-636b-4d9e-bd4b-9385285e4777_24b71bb8b96d45f889278819a3faa076 - 255e00c9-636b-4d9e-bd4b-9385285e4777_24b71bb8b96d45f889278819a3faa076.txt\n",
      "[INFO] Total marked 5 items as treated.                                         \n",
      "[INFO] Processing article: 07ad3357-359f-4f2b-8af1-4514d4cb6949_fce9cb4e842045b49e791f2ae6e0ff86 - 07ad3357-359f-4f2b-8af1-4514d4cb6949_fce9cb4e842045b49e791f2ae6e0ff86.txt\n",
      "[INFO] Total marked 6 items as treated.                                         \n",
      "[INFO] Processing article: 7f44cd9e-d335-4796-b619-1db65bdfd250_7d35f818db334dd3914292e1a3c525d7 - 7f44cd9e-d335-4796-b619-1db65bdfd250_7d35f818db334dd3914292e1a3c525d7.txt\n",
      "[INFO] Total marked 7 items as treated.                                         \n",
      "[INFO] Processing article: f299979b-34b4-4ee3-be16-5fad8c9fafd1_58feacb27f99436eb2ab1200c4824c7e - f299979b-34b4-4ee3-be16-5fad8c9fafd1_58feacb27f99436eb2ab1200c4824c7e.txt\n",
      "[INFO] Total marked 8 items as treated.                                         \n",
      "[INFO] Processing article: 04ae9d1f-f304-404a-8abb-8b35112dfcfa_190d44505c1b4545a1a6f3607a05401a - 04ae9d1f-f304-404a-8abb-8b35112dfcfa_190d44505c1b4545a1a6f3607a05401a.txt\n",
      "[INFO] Total marked 9 items as treated.                                         \n",
      "[INFO] Processing article: 55cc7067-06e3-4b7f-897d-39244217a4f9_a7188e8eadec41308d79700541c218e0 - 55cc7067-06e3-4b7f-897d-39244217a4f9_a7188e8eadec41308d79700541c218e0.txt\n",
      "[INFO] Total marked 10 items as treated.                                        \n",
      "Processing articles:  90%|███████████████████▊  | 9/10 [34:53<03:52, 232.59s/it]\n",
      "[INFO] Processed 10 articles.\n",
      "=== Binary Relevance Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    relevant       0.78      1.00      0.88         7\n",
      "  irrelevant       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.89      0.67      0.69        10\n",
      "weighted avg       0.84      0.80      0.76        10\n",
      "\n",
      "=== Binary Relevance Confusion Matrix ===\n",
      "[[7 0]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "!python ../main.py --limit 10 --evaluate --treated-file relevancy_treated.json --fresh-start --model-path ../../../projet_llama/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf --data-dir ../../data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cabd377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the results\n",
    "import json\n",
    "from pathlib import Path\n",
    "# Load the treated articles\n",
    "treated_file = Path(\"/home/joris/kutniti/article_ai_analyser/tree_questioning/relevancy_treated.json\")\n",
    "with open(treated_file, \"r\") as f:\n",
    "    treated_articles = json.load(f)\n",
    "\n",
    "#remove articles too_short and errors\n",
    "treated_articles = [article for article in treated_articles if article.get(\"predicted_label\") not in [\"too_short\", \"error\"]]\n",
    "\n",
    "#find false positives and false negatives\n",
    "false_positives = [article for article in treated_articles if article.get(\"predicted_label\") == \"positive\" and article.get(\"true_label\") not in [\"positive\", \"neutral\", \"negative\"]]\n",
    "false_negatives = [article for article in treated_articles if article.get(\"predicted_label\") == \"irrelevant\" and article.get(\"true_label\") != \"irrelevant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9a03c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 2\n",
      "False Negatives: 0\n",
      "Total Articles: 10\n",
      "Accuracy: 8 / 10 = 80.00%\n",
      "False Positive Rate: 20.00%\n",
      "False Negative Rate: 0.00%\n",
      "Total Treated Articles: 10\n",
      "Total Articles with Label: 0\n",
      "Ponderated Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "print(f\"False Positives: {len(false_positives)}\")\n",
    "print(f\"False Negatives: {len(false_negatives)}\")\n",
    "print(f\"Total Articles: {len(treated_articles)}\")\n",
    "print(f\"Accuracy: {len(treated_articles) - len(false_positives) - len(false_negatives)} / {len(treated_articles)} = {(len(treated_articles) - len(false_positives) - len(false_negatives)) / len(treated_articles) * 100:.2f}%\")\n",
    "print(f\"False Positive Rate: {len(false_positives) / len(treated_articles) * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {len(false_negatives) / len(treated_articles) * 100:.2f}%\")\n",
    "print(f\"Total Treated Articles: {len(treated_articles)}\")\n",
    "print(f\"Total Articles with Label: {len([article for article in treated_articles if 'label' in article])}\") \n",
    "#ponderated accuracy because there are more relevant articles than irrelevant ones (carefull the prediction \"positive\" goes for the true label [\"positive\", \"neutral\", \"negative\"])\n",
    "true_positive = [article for article in treated_articles if article.get(\"predicted_label\") == \"positive\" and article.get(\"true_label\") in [\"positive\", \"neutral\", \"negative\"]]\n",
    "true_negative = [article for article in treated_articles if article.get(\"predicted_label\") == \"irrelevant\" and article.get(\"true_label\") == \"irrelevant\"]\n",
    "#ratio of true labels to total treated articles\n",
    "real_positive = len([article for article in treated_articles if article.get(\"true_label\") in [\"positive\", \"neutral\", \"negative\"]])\n",
    "real_negative = len([article for article in treated_articles if article.get(\"true_label\") == \"irrelevant\"])\n",
    "ponderated_accuracy = (len(true_positive) / real_positive + len(true_negative) / real_negative) / 2 * 100\n",
    "print(f\"Ponderated Accuracy: {ponderated_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "74561083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the false negatives and false positive in a file\n",
    "with open(\"false_negatives.json\", \"w\") as f:\n",
    "    json.dump(false_negatives, f, indent=4)\n",
    "with open(\"false_positives.json\", \"w\") as f:\n",
    "    json.dump(false_positives, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
